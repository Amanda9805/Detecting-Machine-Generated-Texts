{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amanda9805/Detecting-Machine-Generated-Texts/blob/train-model/Final_project_COS760.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gIBDcyI74-zo"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers adapters datasets fsspec evaluate shap nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfSUUjirjAKg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import evaluate\n",
        "import torch\n",
        "import shap\n",
        "import warnings\n",
        "import datetime\n",
        "from huggingface_hub import login\n",
        "from datasets import load_dataset, Dataset, ClassLabel\n",
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EarlyStoppingCallback, pipeline)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6MdIZgUxRgs"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "POzIGY7h5Pax"
      },
      "outputs": [],
      "source": [
        "#shona_data = load_dataset(\"DigitalUmuganda/AfriVoice\", \"sn\", streaming=True, split=\"train[:10%]\")\n",
        "\n",
        "# english_data = load_dataset(\"oscar-corpus/OSCAR-2201\", language=\"en\", streaming=True)\n",
        "\n",
        "# num_samples = 500\n",
        "# samples = []\n",
        "# for i, example in enumerate(english_data[\"train\"]):\n",
        "#     if i >= num_samples:\n",
        "#         break\n",
        "#     samples.append(example['text'])\n",
        "\n",
        "# eng_df = pd.DataFrame(samples, columns=['text'])\n",
        "# eng_df.head()\n",
        "\n",
        "zulu_data = load_dataset(\"dsfsi/vukuzenzele-monolingual\", \"zul\")\n",
        "\n",
        "def reformatData(dataDict):\n",
        "  langList = []\n",
        "  for index, row in dataDict.iterrows():\n",
        "    # Access data using column names from the row Series\n",
        "    if 'text' in row and row['text']:\n",
        "        langList.append({\n",
        "        'text': row.get('text', ''),\n",
        "        'author': row.get('author', ''),\n",
        "        'title': row.get('title', ''),\n",
        "        'language': 'zul'\n",
        "              })\n",
        "\n",
        "  return langList\n",
        "\n",
        "human_data = reformatData(zulu_data['train'].to_pandas())\n",
        "\n",
        "zul_df = pd.DataFrame(human_data)\n",
        "zul_df['cleaned_text'] = zul_df['text'].apply(clean_text)\n",
        "zul_df['tokens'] = zul_df['cleaned_text'].apply(word_tokenize)\n",
        "zul_df['label'] = 0\n",
        "zul_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rChZLJ-8E1MT"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import json\n",
        "\n",
        "en_generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "\n",
        "english_prompts = [\n",
        "    \"Explain the significance of lobola in Southern Africa\",\n",
        "    \"Write a short dialogue between two friends in Johannesburg\",\n",
        "    \"Describe linguistic features that make isiZulu agglutinative\"\n",
        "]\n",
        "\n",
        "zulu_prompts = [\n",
        "    \"Chaza ngokubaluleka kwesiko lwelobola eNingizimu Afrika\",\n",
        "    \"Bhala inkulumo emfushane phakathi kwabangani ababili eGoli\",\n",
        "    \"Landela indaba yamaZulu ngokomlando\",\n",
        "    \"Chaza ngamasiko amasha eZulu eskhathini samanje\",\n",
        "    \"Bhala inganekwane ethi 'UNogwaja noFudu'\"\n",
        "]\n",
        "\n",
        "# def generate_with_prompts(prompts, generator, language, samples_per_prompt=3):\n",
        "#     data = []\n",
        "#     for prompt in prompts:\n",
        "#         for _ in range(samples_per_prompt):\n",
        "#             output = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n",
        "#             data.append({\n",
        "#                 'prompt': prompt,\n",
        "#                 'text': output[0]['generated_text'],\n",
        "#                 'label': 'machine',\n",
        "#                 'language': language,\n",
        "#                 'prompt_type': 'cultural' if \"tsika\" in prompt else 'linguistic'  # Tag for analysis\n",
        "#             })\n",
        "#     return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# eng_mg_df = generate_with_prompts(english_prompts, en_generator, 'English')\n",
        "# eng_mg_df['cleaned_text'] = eng_mg_df['text'].apply(clean_text)\n",
        "# eng_mg_df['tokens'] = eng_mg_df['cleaned_text'].apply(word_tokenize)\n",
        "# print(eng_mg_df['text'].iloc[0][:300])\n",
        "\n",
        "def load_jsonl_data(file_path):\n",
        "    data = []\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "                if line:  # Skip empty lines\n",
        "                    try:\n",
        "                        data.append(json.loads(line))\n",
        "                    except json.JSONDecodeError as e:\n",
        "                        print(f\"Error parsing JSON line: {e}\")\n",
        "                        continue\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File not found: {file_path}\")\n",
        "        return []\n",
        "\n",
        "    return data\n",
        "\n",
        "zul_mg_df = pd.DataFrame(load_jsonl_data('zulu_mg_text.jsonl'))\n",
        "\n",
        "machine_data =reformatData(zul_mg_df)\n",
        "zul_mg_df = pd.DataFrame(machine_data)\n",
        "zul_mg_df['text'] = zul_mg_df['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "zul_mg_df['language'] = 'zul'\n",
        "zul_mg_df['cleaned_text'] = zul_mg_df['text'].apply(clean_text)\n",
        "zul_mg_df['tokens'] = zul_mg_df['cleaned_text'].apply(word_tokenize)\n",
        "zul_mg_df['label'] = 1\n",
        "\n",
        "zul_mg_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIqYgsMmtYI4"
      },
      "source": [
        "COMBINE THE DATASETS\n",
        "-------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdcTeCfvtXhh"
      },
      "outputs": [],
      "source": [
        "# Combine both datasets, this will be bad for us if we have more than 70% differnce in data length\n",
        "# Combine both datasets\n",
        "all_texts = pd.concat([zul_df, zul_mg_df], ignore_index=True)\n",
        "all_texts_shuffled = all_texts.sample(frac=1).reset_index(drop=True)\n",
        "print(f\"Total texts after combining: {len(all_texts)}\")\n",
        "print(f\"Human-written texts: {len(zul_df)}\")\n",
        "print(f\"Machine-generated texts: {len(zul_mg_df)}\")\n",
        "\n",
        "# Create a DataFrame for easier analysis\n",
        "combined_df = pd.DataFrame(all_texts_shuffled)\n",
        "combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwRW8Jlxt66B"
      },
      "outputs": [],
      "source": [
        "# Create a balanced dataset with equal samples from each class\n",
        "# we can choose to use this of the combined one\n",
        "def create_balanced_dataset(df, target_size_per_class=None):\n",
        "    class_counts = df['label'].value_counts()\n",
        "    min_class_size = class_counts.min()\n",
        "    if target_size_per_class:\n",
        "        sample_size = min(target_size_per_class, min_class_size)\n",
        "    else:\n",
        "        sample_size = min_class_size\n",
        "    balanced_df = df.groupby('label').sample(n=sample_size, random_state=42)\n",
        "    return balanced_df.reset_index(drop=True)\n",
        "\n",
        "# Create balanced dataset, because we need the same number of samples for each class\n",
        "balanced_df = create_balanced_dataset(combined_df)\n",
        "print(f\"\\nBalanced dataset created with {len(balanced_df)} samples\")\n",
        "print(f\"Label distribution in balanced dataset: \\n{balanced_df['label'].value_counts()}\")\n",
        "\n",
        "# Save balanced dataset\n",
        "balanced_output_path = 'balanced_zulu_texts.csv'\n",
        "balanced_df.to_csv(balanced_output_path, index=False, encoding='utf-8')\n",
        "print(f\"Balanced dataset saved to: {balanced_output_path}\")\n",
        "balanced_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfJh3HL9K57I"
      },
      "source": [
        "Model training section\n",
        "----------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yS1jyhV4LAWY"
      },
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the balanced dataset\n",
        "balanced_data_path = 'balanced_zulu_texts.csv'\n",
        "df = pd.read_csv(balanced_data_path, encoding='utf-8')\n",
        "\n",
        "# Convert pandas DataFrame to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df[['text', 'label']])\n",
        "\n",
        "# Cast the 'label' column to ClassLabel\n",
        "dataset = dataset.cast_column('label', ClassLabel(num_classes=2, names=['human', 'machine']))\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_val_split = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "train_dataset = train_val_split['train']\n",
        "val_dataset = train_val_split['test']\n",
        "\n",
        "# Load AfroXLMR tokenizer\n",
        "model_name = \"Davlan/afro-xlmr-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Load AfroXLMR model for sequence classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=2,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Define metrics for evaluation\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "    return {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1': f1['f1']\n",
        "    }\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./afroxlmr_finetuned',\n",
        "    run_name='/afroxlmr_finetune_zulu',  # too much warnings so better to use a custom run name\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),  # Enable mixed precision only if GPU is available\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Initialize data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model and tokenizer\n",
        "model.save_pretrained('./afroxlmr_finetuned/model')\n",
        "tokenizer.save_pretrained('./afroxlmr_finetuned/tokenizer')\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7vmU2OCycf-B"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Free memory before starting\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "# It's better to load the model through the Trainer if possible to use its prediction capabilities\n",
        "model_path = './afroxlmr_finetuned'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(os.path.join(model_path, 'model'))\n",
        "tokenizer = AutoTokenizer.from_pretrained(os.path.join(model_path, 'tokenizer'))\n",
        "\n",
        "# Move model to GPU if available (Trainer handles this, but good practice)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Load the balanced dataset\n",
        "balanced_data_path = 'balanced_zulu_texts.csv'\n",
        "df = pd.read_csv(balanced_data_path, encoding='utf-8')\n",
        "\n",
        "# Convert to Hugging Face Dataset\n",
        "dataset = Dataset.from_pandas(df[['text', 'label']])\n",
        "dataset = dataset.cast_column('label', ClassLabel(num_classes=2, names=['human', 'machine']))\n",
        "\n",
        "# Split into train and validation sets\n",
        "# Use the same split as training to ensure consistency\n",
        "train_val_split = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "val_dataset = train_val_split['test']\n",
        "\n",
        "# Define the same tokenization function as used for training\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "# Tokenize the validation dataset\n",
        "val_dataset_tokenized = val_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Set format for PyTorch\n",
        "val_dataset_tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Initialize data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Re-initialize the Trainer with the fine-tuned model and tokenizer\n",
        "# allow using trainer.predict for consistent evaluation\n",
        "training_args_eval = TrainingArguments(\n",
        "    output_dir='/tmp/eval_output',\n",
        "    per_device_eval_batch_size=8,\n",
        "    report_to=\"none\",\n",
        "    no_cuda=not torch.cuda.is_available()\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args_eval,\n",
        "    eval_dataset=val_dataset_tokenized,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "\n",
        "# Function to compute linguistic features\n",
        "# I dont know copying code\n",
        "def compute_linguistic_features(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Lexical diversity (TTR: Type-Token Ratio)\n",
        "    ttr = len(set(tokens)) / len(tokens) if tokens else 0\n",
        "    # Top 5 bigrams\n",
        "    bigrams = list(nltk.bigrams(tokens))\n",
        "    bigram_freq = Counter(bigrams).most_common(5)\n",
        "    # Text length\n",
        "    text_length = len(tokens)\n",
        "    return {\n",
        "        'ttr': ttr,\n",
        "        'top_bigrams': bigram_freq,\n",
        "        'text_length': text_length\n",
        "    }\n",
        "\n",
        "# Error analysis using trainer.predict\n",
        "def perform_error_analysis(trainer, val_dataset):\n",
        "    # Use trainer.predict to get predictions\n",
        "    predictions_output = trainer.predict(val_dataset)\n",
        "    logits = predictions_output.predictions\n",
        "    true_labels = predictions_output.label_ids\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    errors = []\n",
        "    texts = val_dataset['text'] # Get original texts for features\n",
        "\n",
        "    for idx, (text, true_label, pred_label) in enumerate(zip(texts, true_labels, predictions)):\n",
        "        if pred_label != true_label:\n",
        "            features = compute_linguistic_features(text)\n",
        "            errors.append({\n",
        "                'index': idx,\n",
        "                'text': text,\n",
        "                'true_label': 'machine' if true_label == 1 else 'human',\n",
        "                'pred_label': 'machine' if pred_label == 1 else 'human',\n",
        "                'ttr': features['ttr'],\n",
        "                'top_bigrams': features['top_bigrams'],\n",
        "                'text_length': features['text_length']\n",
        "            })\n",
        "\n",
        "    # Compute precision, recall, F1 using sklearn on numpy arrays\n",
        "    from sklearn.metrics import precision_recall_fscore_support\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        true_labels, predictions, average='weighted'\n",
        "    )\n",
        "\n",
        "    return errors, {'precision': precision, 'recall': recall, 'f1': f1}\n",
        "\n",
        "# SHAP explainability analysis using a prediction function compatible with SHAP\n",
        "def shap_analysis(val_dataset, model, tokenizer, device, num_samples=10):\n",
        "    # Select a subset of validation texts and their corresponding true labels\n",
        "    texts = val_dataset['text'][:num_samples]\n",
        "    labels = val_dataset['label'][:num_samples]\n",
        "\n",
        "    # Define a prediction function for SHAP that takes raw text and returns probabilities\n",
        "    def predict_proba(texts):\n",
        "        # Tokenize inputs manually for the SHAP explainer\n",
        "        inputs = tokenizer(\n",
        "            list(texts),\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # Move inputs to the device\n",
        "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "        # Get model outputs (logits)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Convert logits to probabilities (softmax)\n",
        "        probs = torch.softmax(logits, dim=-1).cpu().numpy()\n",
        "        return probs\n",
        "\n",
        "    # Initialize SHAP explainer\n",
        "    # Use the predict_proba function and a masker\n",
        "    explainer = shap.Explainer(predict_proba, shap.maskers.Text(tokenizer, mask_token='<unk>'), output_names=['human', 'machine'])\n",
        "\n",
        "    # Compute SHAP values\n",
        "    shap_values = explainer(texts)\n",
        "\n",
        "    # Save SHAP plots\n",
        "    output_dir = '/content/drive/MyDrive/shap_plots'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(len(texts)):\n",
        "        # Use shap.plots.text for text explanations\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        shap.plots.waterfall(shap_values[i, :, 1])\n",
        "        plt.savefig(os.path.join(output_dir, f'shap_text_{i}.png'), bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "    return shap_values\n",
        "\n",
        "# Summarize findings\n",
        "def summarize_findings(errors, metrics, output_file='/content/drive/MyDrive/evaluation_report.txt'):\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"Phase 3: Evaluation and Analysis Report\\n\")\n",
        "        f.write(\"=====================================\\n\\n\")\n",
        "\n",
        "        f.write(\"1. Model Performance Metrics\\n\")\n",
        "        f.write(f\"Precision: {metrics['precision']:.4f}\\n\")\n",
        "        f.write(f\"Recall: {metrics['recall']:.4f}\\n\")\n",
        "        f.write(f\"F1-Score: {metrics['f1']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"2. Error Analysis\\n\")\n",
        "        if errors:\n",
        "            f.write(f\"Number of misclassifications: {len(errors)}\\n\")\n",
        "            for error in errors:\n",
        "                f.write(f\"Index: {error['index']}\\n\")\n",
        "                f.write(f\"Text: {error['text'][:500]}...\\n\") # Increased text preview\n",
        "                f.write(f\"True Label: {error['true_label']}\\n\")\n",
        "                f.write(f\"Predicted Label: {error['pred_label']}\\n\")\n",
        "                f.write(f\"TTR: {error['ttr']:.4f}\\n\")\n",
        "                f.write(f\"Top Bigrams: {error['top_bigrams']}\\n\")\n",
        "                f.write(f\"Text Length: {error['text_length']}\\n\")\n",
        "                f.write(\"-\" * 50 + \"\\n\")\n",
        "        else:\n",
        "            f.write(\"No misclassifications found in the validation set.\\n\\n\")\n",
        "\n",
        "        f.write(\"3. SHAP Explainability Analysis\\n\")\n",
        "        f.write(\"SHAP plots have been saved to /content/drive/MyDrive/shap_plots/\\n\")\n",
        "        f.write(\"Review saved plots for detailed token-level contributions.\\n\\n\")\n",
        "\n",
        "        f.write(\"4. Patterns of Success and Failure\\n\")\n",
        "        f.write(\"- Model achieved performance as indicated by metrics.\\n\")\n",
        "        if errors:\n",
        "             f.write(f\"- Errors occurred on {len(errors)} samples. Review error analysis for patterns.\\n\")\n",
        "             f.write(\"- Linguistic features of misclassified texts might reveal insights (e.g., very short/long texts, unusual vocabulary).\\n\")\n",
        "        else:\n",
        "            f.write(\"- No misclassifications observed in the validation set, which could indicate excellent performance or potential overfitting on a small dataset.\\n\")\n",
        "        f.write(\"- SHAP analysis helps understand which tokens influenced the model's decisions for the tested samples.\\n\")\n",
        "        f.write(\"- Future work: Evaluate on a larger, more diverse dataset and potentially cross-lingual settings.\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# Use the trainer to predict on the tokenized validation dataset\n",
        "errors, metrics = perform_error_analysis(trainer, val_dataset_tokenized)\n",
        "\n",
        "# Perform SHAP analysis using the original val_dataset for texts\n",
        "# Pass the loaded model, tokenizer, and device to the SHAP function\n",
        "shap_values = shap_analysis(val_dataset, model, tokenizer, device, num_samples=min(10, len(val_dataset))) # Limit SHAP samples\n",
        "\n",
        "# Summarize findings (SHAP values object is not directly summarized in the report text)\n",
        "summarize_findings(errors, metrics)\n",
        "\n",
        "# Free memory\n",
        "del model, trainer, val_dataset, val_dataset_tokenized # Remove classifier as it's no longer used for analysis\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "print(\"Evaluation and analysis complete. Report saved to /content/drive/MyDrive/evaluation_report.txt\")\n",
        "print(f\"SHAP plots saved to /content/drive/MyDrive/shap_plots/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC1lL7pS05gn"
      },
      "source": [
        "Section for Zero-shot\n",
        "---------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "untTH0mO4X56"
      },
      "outputs": [],
      "source": [
        "# Load English dataset\n",
        "eng_data = load_dataset(\"dsfsi/vukuzenzele-monolingual\", \"eng\")\n",
        "\n",
        "eng_human_data = reformatData(eng_data['train'].to_pandas())\n",
        "\n",
        "eng_df = pd.DataFrame(eng_human_data)\n",
        "eng_df['cleaned_text'] = eng_df['text'].apply(clean_text)\n",
        "eng_df['tokens'] = eng_df['cleaned_text'].apply(word_tokenize)\n",
        "eng_df['label'] = 0\n",
        "eng_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmkRGkGt4xOX"
      },
      "outputs": [],
      "source": [
        "eng_mg_df = pd.DataFrame(load_jsonl_data('eng_mg_data.jsonl'))\n",
        "\n",
        "eng_machine_data =reformatData(eng_mg_df)\n",
        "eng_mg_df = pd.DataFrame(eng_machine_data)\n",
        "eng_mg_df['text'] = eng_mg_df['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
        "eng_mg_df['language'] = 'eng'\n",
        "eng_mg_df['cleaned_text'] = eng_mg_df['text'].apply(clean_text)\n",
        "eng_mg_df['tokens'] = eng_mg_df['cleaned_text'].apply(word_tokenize)\n",
        "eng_mg_df['label'] = 1\n",
        "\n",
        "eng_mg_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxR7WtmhEC36"
      },
      "outputs": [],
      "source": [
        "all_eng_texts = pd.concat([eng_df, eng_mg_df], ignore_index=True)\n",
        "all_eng_texts_shuffled = all_eng_texts.sample(frac=1).reset_index(drop=True)\n",
        "print(f\"Total texts after combining: {len(all_eng_texts)}\")\n",
        "print(f\"Human-written texts: {len(eng_df)}\")\n",
        "print(f\"Machine-generated texts: {len(eng_mg_df)}\")\n",
        "\n",
        "# Create a DataFrame for easier analysis\n",
        "eng_combined_df = pd.DataFrame(all_eng_texts_shuffled)\n",
        "eng_combined_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIpkQrUKHG1q"
      },
      "outputs": [],
      "source": [
        "eng_balanced_df = create_balanced_dataset(eng_combined_df)\n",
        "print(f\"\\nBalanced dataset created with {len(eng_balanced_df)} samples\")\n",
        "print(f\"Label distribution in balanced dataset: \\n{eng_balanced_df['label'].value_counts()}\")\n",
        "\n",
        "# Save balanced dataset\n",
        "balanced_output_path = 'balanced_english_texts.csv'\n",
        "eng_balanced_df.to_csv(balanced_output_path, index=False, encoding='utf-8')\n",
        "print(f\"Balanced dataset saved to: {balanced_output_path}\")\n",
        "eng_balanced_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJeo5xXR0uch"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Fine-tune on English Data\n",
        "\n",
        "english_data_path = 'balanced_english_texts.csv'\n",
        "df_english = pd.read_csv(english_data_path, encoding='utf-8')\n",
        "dataset_english = Dataset.from_pandas(df_english[['text', 'label']])\n",
        "dataset_english = dataset_english.cast_column('label', ClassLabel(num_classes=2, names=['human', 'machine']))\n",
        "\n",
        "# Split into train and validation sets\n",
        "train_val_split = dataset_english.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "train_dataset = train_val_split['train']\n",
        "val_dataset = train_val_split['test']\n",
        "\n",
        "# Load tokenizer and model\n",
        "model_name = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples['text'],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "# Tokenize datasets\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
        "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "val_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "# Define evaluation metrics\n",
        "accuracy_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
        "    return {\n",
        "        'accuracy': accuracy['accuracy'],\n",
        "        'f1': f1['f1']\n",
        "    }\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./english_finetuned',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained('./english_finetuned/model')\n",
        "tokenizer.save_pretrained('./english_finetuned/tokenizer')\n",
        "\n",
        "# Zero-Shot Evaluation on Shona and isiZulu\n",
        "def evaluate_zero_shot(language, data_path):\n",
        "    # Load dataset\n",
        "    df_lang = pd.read_csv(data_path, encoding='utf-8')\n",
        "    dataset_lang = Dataset.from_pandas(df_lang[['text', 'label']])\n",
        "    dataset_lang = dataset_lang.cast_column('label', ClassLabel(num_classes=2, names=['human', 'machine']))\n",
        "\n",
        "    # Tokenize\n",
        "    eval_dataset = dataset_lang.map(tokenize_function, batched=True)\n",
        "    eval_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    # Evaluate\n",
        "    results = trainer.evaluate(eval_dataset)\n",
        "    print(f\"{language} Zero-Shot Evaluation Results: {results}\")\n",
        "\n",
        "\n",
        "# Evaluate on isiZulu\n",
        "zulu_data_path = 'balanced_zulu_texts.csv'\n",
        "evaluate_zero_shot(\"isiZulu\", zulu_data_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmgTqJnukb13"
      },
      "outputs": [],
      "source": [
        "# Suppress verbose warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configuration\n",
        "# Store model paths in a dictionary for easier access\n",
        "MODELS_INFO = {\n",
        "    'eng': {'path': './english_finetuned'},\n",
        "    'zul': {'path': './afroxlmr_finetuned'}\n",
        "}\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "ID2LABEL = {0: 'Human-Generated', 1: 'Machine-Generated'}\n",
        "LABEL2ID = {v: k for k, v in ID2LABEL.items()}\n",
        "SHAP_PLOTS_DIR = 'shap_explanations'\n",
        "\n",
        "\n",
        "# store loaded models on the CPU to avoid re-loading from disk\n",
        "MODELS_CACHE = {}\n",
        "\n",
        "# Create the directory for SHAP plots if it doesn't exist\n",
        "os.makedirs(SHAP_PLOTS_DIR, exist_ok=True)\n",
        "\n",
        "def get_or_load_model(lang_key, device):\n",
        "\n",
        "    # Iterate through any models already in the cache\n",
        "    for key, cached_data in MODELS_CACHE.items():\n",
        "        # If there's a model on the GPU that is NOT the one we want, move it to CPU\n",
        "        if key != lang_key and cached_data['model'].device.type == 'cuda':\n",
        "            print(f\"Moving '{key}' model to CPU to free up VRAM...\")\n",
        "            cached_data['model'].to('cpu')\n",
        "\n",
        "    # Force Python's garbage collector and empty PyTorch's cache\n",
        "    gc.collect()\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # Get the requested model\n",
        "    if lang_key in MODELS_CACHE:\n",
        "        # Model is already in our cache (on the CPU), just retrieve it\n",
        "        print(f\"Loading '{lang_key}' model from cache...\")\n",
        "        model = MODELS_CACHE[lang_key]['model']\n",
        "        tokenizer = MODELS_CACHE[lang_key]['tokenizer']\n",
        "    else:\n",
        "        # Model is not cached, load it from disk\n",
        "        print(f\"Loading '{lang_key}' model from disk...\")\n",
        "        model_path_info = MODELS_INFO.get(lang_key)\n",
        "        if not model_path_info:\n",
        "            print(f\"Error: No model path configured for language '{lang_key}'.\")\n",
        "            return None, None\n",
        "\n",
        "        model_dir = os.path.join(model_path_info['path'], 'model')\n",
        "        tokenizer_dir = os.path.join(model_path_info['path'], 'tokenizer')\n",
        "\n",
        "        if not os.path.exists(model_dir) or not os.path.exists(tokenizer_dir):\n",
        "            print(f\"Error: Model or tokenizer not found at '{model_path_info['path']}'.\")\n",
        "            print(\"Please ensure you have trained and saved the models as per the notebook.\")\n",
        "            return None, None\n",
        "\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
        "\n",
        "        # Store the newly loaded model and tokenizer in the cache\n",
        "        MODELS_CACHE[lang_key] = {'model': model, 'tokenizer': tokenizer}\n",
        "\n",
        "    # Move the requested model to the target device (GPU/CPU)\n",
        "    if model.device.type != device.type:\n",
        "        print(f\"Moving '{lang_key}' model to {device.type.upper()}...\")\n",
        "        model.to(device)\n",
        "\n",
        "    model.eval()\n",
        "    print(\"...model is ready.\")\n",
        "    return model, tokenizer\n",
        "\n",
        "\n",
        "def predict_and_explain(text, model, tokenizer, device):\n",
        "    # Prediction\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    probabilities = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
        "    prediction_idx = np.argmax(probabilities)\n",
        "    predicted_label = ID2LABEL[prediction_idx]\n",
        "    confidence = probabilities[prediction_idx]\n",
        "\n",
        "    # SHAP Explanation\n",
        "    print(\"\\nGenerating SHAP explanation... (this may take a moment)\")\n",
        "\n",
        "    def predict_proba_for_shap(texts):\n",
        "        if isinstance(texts, np.ndarray):\n",
        "            texts = texts.tolist()\n",
        "        inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        return torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "\n",
        "    explainer = shap.Explainer(predict_proba_for_shap, shap.maskers.Text(tokenizer, mask_token=\"<unk>\"), output_names=list(ID2LABEL.values()))\n",
        "    shap_values = explainer([text])\n",
        "\n",
        "    # Generate and Save SHAP Plot\n",
        "    class_index_to_explain = LABEL2ID['Machine-Generated']\n",
        "    plt.figure()\n",
        "    shap.plots.waterfall(shap_values[0, :, class_index_to_explain], show=False)\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    plot_filename = f\"shap_explanation_{lang_key}_{timestamp}.png\"\n",
        "    plot_path = os.path.join(SHAP_PLOTS_DIR, plot_filename)\n",
        "\n",
        "    plt.savefig(plot_path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"...explanation saved to {plot_path}\")\n",
        "\n",
        "    return predicted_label, confidence, plot_path\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the interactive detector.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\" Human vs. Machine Text Detector for English & isiZulu\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Running on device: {str(DEVICE).upper()}\")\n",
        "\n",
        "    global lang_key # Make lang_key accessible to predict_and_explain for file naming\n",
        "\n",
        "    while True:\n",
        "        # Get User Input\n",
        "        lang_choice = \"\"\n",
        "        while lang_choice not in ['1', '2']:\n",
        "            lang_choice = input(\"\\nChoose a language:\\n  1: English\\n  2: isiZulu\\nEnter choice (1 or 2): \")\n",
        "\n",
        "        lang_key = 'eng' if lang_choice == '1' else 'zul'\n",
        "\n",
        "        # Load model on-demand\n",
        "        model, tokenizer = get_or_load_model(lang_key, DEVICE)\n",
        "\n",
        "        # Check if the model failed to load\n",
        "        if model is None:\n",
        "            break # Exit if a model path is incorrect\n",
        "\n",
        "        input_text = input(f\"\\nPlease enter the {lang_key.upper()} text you want to analyze:\\n> \")\n",
        "\n",
        "        if not input_text.strip():\n",
        "            print(\"Error: Input text cannot be empty.\")\n",
        "            continue\n",
        "\n",
        "        # Perform Analysis\n",
        "        print(\"\\nAnalyzing text...\")\n",
        "        predicted_label, confidence, plot_path = predict_and_explain(\n",
        "            input_text, model, tokenizer, DEVICE\n",
        "        )\n",
        "\n",
        "        # Display Results\n",
        "        print(\"\\n\" + \"-\"*25 + \" ANALYSIS RESULTS \" + \"-\"*25)\n",
        "        print(f\"  Prediction: The text is likely {predicted_label.upper()}\")\n",
        "        print(f\"  Confidence: {confidence:.2%}\")\n",
        "        print(f\"\\nAn explanation plot has been saved here: {plot_path}\")\n",
        "        print(\"-\" * 70)\n",
        "\n",
        "        # Loop Control\n",
        "        another = input(\"\\nWould you like to analyze another text? (y/n): \").lower()\n",
        "        if another != 'y':\n",
        "            print(\"\\nThank you for using the detector. Goodbye!\")\n",
        "            break\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jHUtyxhoKS-"
      },
      "outputs": [],
      "source": [
        "# SECOND TEST\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model_path = \"./afroxlmr_finetuned/model\"\n",
        "tokenizer_path = \"./afroxlmr_finetuned/tokenizer\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
        "\n",
        "# Create a text classification pipeline\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0 if torch.cuda.is_available() else -1,  # Use GPU if available\n",
        "    return_all_scores=True\n",
        ")\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {0: \"human\", 1: \"machine\"}\n",
        "\n",
        "# Function to predict and explain\n",
        "def predict_and_explain(text):\n",
        "    # Predict\n",
        "    prediction = classifier(text)[0]\n",
        "    predicted_label = label_mapping[int(prediction[0][\"label\"].split(\"_\")[1])]\n",
        "    human_prob = prediction[0][\"score\"] if predicted_label == \"human\" else prediction[1][\"score\"]\n",
        "    machine_prob = prediction[1][\"score\"] if predicted_label == \"human\" else prediction[0][\"score\"]\n",
        "\n",
        "    # SHAP Explanation\n",
        "    explainer = shap.Explainer(classifier)\n",
        "    shap_values = explainer([text])\n",
        "\n",
        "    # Extract SHAP values for the predicted class\n",
        "    predicted_class_idx = 0 if predicted_label == \"human\" else 1\n",
        "    shap_values_for_predicted_class = shap_values[0, :, predicted_class_idx]\n",
        "\n",
        "    # Format results\n",
        "    result = {\n",
        "        \"text\": text,\n",
        "        \"predicted_label\": predicted_label,\n",
        "        \"human_probability\": human_prob,\n",
        "        \"machine_probability\": machine_prob,\n",
        "        \"shap_values\": shap_values_for_predicted_class\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nInput Text: {text}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\")\n",
        "    print(f\"Human Probability: {human_prob:.4f}\")\n",
        "    print(f\"Machine Probability: {machine_prob:.4f}\")\n",
        "    print(\"\\nSHAP Explanation:\")\n",
        "    shap.plots.text(shap_values[0, :, :])\n",
        "\n",
        "    return result\n",
        "\n",
        "# Interactive input loop\n",
        "def main():\n",
        "    print(\"Text Classification and SHAP Explanation Tool\")\n",
        "    print(\"Enter text to classify as human or machine-generated. Type 'exit' to quit.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nEnter text: \").strip()\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "        if not user_input:\n",
        "            print(\"Please enter some text.\")\n",
        "            continue\n",
        "\n",
        "        # Predict and explain\n",
        "        predict_and_explain(user_input)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}